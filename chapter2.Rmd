# Regression and model validation
 + This week course excersie will focus on Regression analyses and running the model for the data of our interest. 
 + Prior to regression and model validation, we looked deep into the data, understood it attributes and have worked with redefining name of some varibales and created a subset by seleccting variables of our interest for further analyses.  

##Reading the data
```{r}
setwd("~/IODS-project")
learning2014 <- read.table("~/IODS-project/data/learning2014.txt") 
str(learning2014) 
dim(learning2014) 
```


###Comment on structure and dimension of the data
 + The data frame contains 7 variables with 166 observations where age and points are presented as integers and attitude, deep, stra and surf are presented as numbers. 
 + Gender is presented with two factor levels, male (M) and female (F).

##Exploring the data 
```{r}
pairs(learning2014[!names(learning2014) %in% c("gender")],col=learning2014$gender)
```
 

```{r}
library(GGally)
library(ggplot2)
ggpairs(learning2014, 
        mapping = aes(col = gender, alpha = 0.3), 
        lower = list(combo = wrap("facethist", bins = 20)))
```

###Interpreting the data 
 + If we look at the main daiganol (skewed distribution) and first column (histograms), among all variables ***age*** of the gender is highly skewed whereas ***stra*** is skewed very minimal. 
 + High skeweness in age is also visible from box plots as it shows many outliers above whiskers (error bars). Minimal skweness in ***stra*** variable could be also seen in the box plot of ***stra*** where medians for both genders lies almost at the center of the box. 
 + Highest correlation is seen between ***attitude*** and ***points***; **Cor:** `r    cor(learning2014$attitude,learning2014$points)` .
 + Lowest correlation is seen between ***deep*** and ***surf***; **Cor:** `r    cor(learning2014$deep,learning2014$surf)` .

##Linear Regression
```{r}
qplot(attitude, points, data = learning2014) + geom_smooth(method = "lm")
```

Running the regression model for  with three independent variables, ***attitude***, ***surf***, and ***deep*** to identify the strongest impact of them on ***points***.
```{r}
my_model <- lm(points ~ attitude + surf + deep, data = learning2014)
results <- summary(my_model)

knitr::kable(results$coefficients, digits=3, caption="Regression coefficients")
```




